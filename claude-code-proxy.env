# Required API Keys
ANTHROPIC_API_KEY="ignored-ansi-uses-network-auth"
#OPENAI_API_KEY="sk-... put your LiteLLM virtual key"
GEMINI_API_KEY="ignored-not-needed"
# GROQ_API_KEY="gsk_... maybe your groq key here"

# Use OpenAI provider since your ANSI endpoint is OpenAI-compatible
PREFERRED_PROVIDER="openai"

# Point to your ANSI Bedrock endpoint instead of OpenAI
OPENAI_BASE_URL="http://localhost:4000/v1"
# OPENAI_BASE_URL="https://llm-api-access.my-endpoint.example.com/v1"

# Map to your actual ANSI model
# Since you only have one model available, use it for both big and small
BIG_MODEL="groq-gpt-oss-120b"
SMALL_MODEL="groq-llama-3-8b"
## This didn't work! Tool calls went nowhere
# BIG_MODEL="groq-meta-llama-4-maverick"
# SMALL_MODEL="groq-meta-llama-4-scout"

# Optional: Provider Preference and Model Mapping
# Controls which provider (google, openai, or anthropic) is preferred for mapping haiku/sonnet.
# Defaults to openai if not set.
# Set to "anthropic" for "just an Anthropic proxy" mode (no remapping)
PREFERRED_PROVIDER="openai"
